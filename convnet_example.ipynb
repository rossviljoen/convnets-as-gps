{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "armed-maria",
   "metadata": {},
   "source": [
    "## Setup & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-edmonton",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from typing import Dict, Optional, Tuple\n",
    "from gpflow.utilities import to_default_float\n",
    "import gpflow\n",
    "import numpy as np\n",
    "\n",
    "gpflow.config.set_default_float(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-photographer",
   "metadata": {},
   "source": [
    "Import MNIST and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-agenda",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset, info = tfds.load(name=\"mnist\", split=tfds.Split.TRAIN, with_info=True)\n",
    "\n",
    "total_num_data = info.splits[\"train\"].num_examples\n",
    "image_shape = info.features[\"image\"].shape\n",
    "image_size = tf.reduce_prod(image_shape)\n",
    "num_classes = info.features[\"label\"].num_classes\n",
    "batch_size = 32\n",
    "\n",
    "# reshape each input x to [1, 28, 28] and normalise to (0, 1).\n",
    "# one-hot encode the outputs to [1, 10].\n",
    "# x and y have a leading dim of 1 so that the concat in the next cell works\n",
    "def map_fn(input_slice: Dict[str, tf.Tensor]):\n",
    "    updated = input_slice\n",
    "    image = to_default_float(updated[\"image\"]) / 255.0\n",
    "    label = tf.expand_dims(tf.one_hot(updated[\"label\"], num_classes), 0)\n",
    "    return tf.reshape(image, [-1, 28, 28]), label\n",
    "\n",
    "autotune = tf.data.experimental.AUTOTUNE\n",
    "dataset = (\n",
    "    original_dataset.shuffle(1024)\n",
    "    .take(150)\n",
    "    # .batch(batch_size, drop_remainder=True)\n",
    "    .map(map_fn, num_parallel_calls=autotune)\n",
    "    .prefetch(autotune)\n",
    "    # .repeat()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-cowboy",
   "metadata": {},
   "source": [
    "Turn the dataset into usable tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-settlement",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for (x, y) in dataset:\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "X = tf.concat(X, 0)\n",
    "Y = tf.concat(Y, 0)\n",
    "X_train, X_test = X[:100], X[100:]\n",
    "Y_train, Y_test = Y[:100], Y[100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-crown",
   "metadata": {},
   "source": [
    "## Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deep_ckern as dkern\n",
    "\n",
    "def create_kern():\n",
    "    return dkern.DeepKernel(\n",
    "        [1, 28, 28],\n",
    "        filter_sizes=[[5, 5], [2, 2], [5, 5], [2, 2]],\n",
    "        recurse_kern=dkern.ExReLU(multiply_by_sqrt2=True),\n",
    "        var_weight=1.,\n",
    "        var_bias=1.,\n",
    "        padding=[\"VALID\", \"SAME\", \"VALID\", \"SAME\"],\n",
    "        strides=[[1, 1]] * 4,\n",
    "        data_format=\"NCHW\",\n",
    "        skip_freq=-1,\n",
    "    )\n",
    "\n",
    "kern = create_kern()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-document",
   "metadata": {},
   "source": [
    "Compute the training covariance $K_{xx}$ and train-test cross covariance $K_{zx}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "Kxx = kern.K(X_train)\n",
    "Kzx = kern.K(X_test, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-membrane",
   "metadata": {},
   "source": [
    "Treat the classification as a multi-output regression problem (with independent outputs) and solve for the predictive means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_inv_Y = tf.linalg.solve(Kxx, Y_train)\n",
    "pred_means = tf.linalg.matmul(Kzx, K_inv_Y)\n",
    "\n",
    "Y_pred = tf.one_hot(tf.math.argmax(pred_means, axis=1), 10)\n",
    "corrects = tf.reduce_all(Y_pred == Y_test, axis=1)\n",
    "accuracy = (tf.math.count_nonzero(corrects) / len(corrects)).numpy()\n",
    "\n",
    "print(accuracy) # 82%"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}